{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3db580e3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-04T14:44:49.070504Z",
     "iopub.status.busy": "2024-03-04T14:44:49.069894Z",
     "iopub.status.idle": "2024-03-04T14:44:50.039932Z",
     "shell.execute_reply": "2024-03-04T14:44:50.038641Z"
    },
    "papermill": {
     "duration": 0.978011,
     "end_time": "2024-03-04T14:44:50.043104",
     "exception": false,
     "start_time": "2024-03-04T14:44:49.065093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           X1        X2        X3  X4        X5    target\n",
      "0    1.764052  0.821904  0.090332   0 -0.361672  5.869385\n",
      "1    0.400157  0.700529  3.718693   1  2.153720  8.518218\n",
      "2    0.978738  0.883078 -3.252644   1  0.847408 -0.271896\n",
      "3    2.240893  0.966575 -0.269645   1 -0.198720  7.664519\n",
      "4    1.867558  0.774748 -1.168187   0  1.575307  3.954908\n",
      "..        ...       ...       ...  ..       ...       ...\n",
      "995  0.412871  0.503528 -1.909886   1 -1.037881 -0.759389\n",
      "996 -0.198399  0.620842 -2.940803   1  0.346979 -2.346040\n",
      "997  0.094192  0.832988  2.020855   0  0.252031  5.938620\n",
      "998 -1.147611  0.564597  0.992359   1  1.750919  0.747540\n",
      "999 -0.358114  0.090969  1.153912   1 -0.418401  1.266151\n",
      "\n",
      "[1000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Generate a sample dataset\n",
    "num_samples = 1000\n",
    "\n",
    "# Generate predictor variables\n",
    "X1 = np.random.normal(loc=0, scale=1, size=num_samples)\n",
    "X2 = np.random.uniform(low=0, high=1, size=num_samples)\n",
    "X3 = np.random.normal(loc=0, scale=2, size=num_samples)\n",
    "X4 = np.random.randint(low=0, high=2, size=num_samples)\n",
    "X5 = np.random.normal(loc=0, scale=1, size=num_samples)\n",
    "\n",
    "# Generate noise variable\n",
    "noise = np.random.normal(loc=0, scale=0.5, size=num_samples)\n",
    "\n",
    "# Generate target variable\n",
    "# Let's assume a linear relationship with some noise\n",
    "target = 2*X1 + 3*X2 + 1.5*X3 + 0.5*X4 + noise\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'X1': X1,\n",
    "    'X2': X2,\n",
    "    'X3': X3,\n",
    "    'X4': X4,\n",
    "    'X5': X5,\n",
    "    'target': target\n",
    "})\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a39d81a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T14:44:50.050391Z",
     "iopub.status.busy": "2024-03-04T14:44:50.049885Z",
     "iopub.status.idle": "2024-03-04T14:44:53.358272Z",
     "shell.execute_reply": "2024-03-04T14:44:53.356671Z"
    },
    "papermill": {
     "duration": 3.31461,
     "end_time": "2024-03-04T14:44:53.360805",
     "exception": false,
     "start_time": "2024-03-04T14:44:50.046195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.984\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.984\n",
      "Method:                 Least Squares   F-statistic:                          1.536e+04\n",
      "Date:                Mon, 04 Mar 2024   Prob (F-statistic):                        0.00\n",
      "Time:                        14:44:53   Log-Likelihood:                         -721.28\n",
      "No. Observations:                1000   AIC:                                      1451.\n",
      "Df Residuals:                     996   BIC:                                      1470.\n",
      "Df Model:                           4                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             1.9799      0.016    123.402      0.000       1.948       2.011\n",
      "x2             3.0307      0.034     88.475      0.000       2.963       3.098\n",
      "x3             1.5169      0.008    184.205      0.000       1.501       1.533\n",
      "x4             0.5068      0.028     18.146      0.000       0.452       0.562\n",
      "==============================================================================\n",
      "Omnibus:                        0.586   Durbin-Watson:                   1.950\n",
      "Prob(Omnibus):                  0.746   Jarque-Bera (JB):                0.669\n",
      "Skew:                          -0.017   Prob(JB):                        0.716\n",
      "Kurtosis:                       2.878   Cond. No.                         4.89\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Add constant for intercept\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X = sm.add_constant(data.drop('target', axis=1))\n",
    "y = data['target']\n",
    "\n",
    "# Apply backward elimination\n",
    "def backward_elimination(X, y, significance_level=0.05):\n",
    "    num_features = X.shape[1]\n",
    "    for i in range(num_features):\n",
    "        regressor_OLS = sm.OLS(y, X).fit()\n",
    "        max_p_value = max(regressor_OLS.pvalues)\n",
    "        if max_p_value > significance_level:\n",
    "            index_to_remove = np.argmax(regressor_OLS.pvalues)\n",
    "            X = np.delete(X, index_to_remove, 1)\n",
    "        else:\n",
    "            break\n",
    "    return X, regressor_OLS\n",
    "\n",
    "X_optimal, regressor_OLS = backward_elimination(X.values, y.values)\n",
    "\n",
    "# Print summary of the final model\n",
    "print(regressor_OLS.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d664c991",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T14:44:53.367696Z",
     "iopub.status.busy": "2024-03-04T14:44:53.367166Z",
     "iopub.status.idle": "2024-03-04T14:44:53.748254Z",
     "shell.execute_reply": "2024-03-04T14:44:53.746345Z"
    },
    "papermill": {
     "duration": 0.386988,
     "end_time": "2024-03-04T14:44:53.750376",
     "exception": false,
     "start_time": "2024-03-04T14:44:53.363388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 1.5760189069635189\n",
      "Coefficients: [ 0.00813622 -0.06484184]\n"
     ]
    }
   ],
   "source": [
    "# Create feature matrix X and target vector y\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Define a function to perform backward elimination\n",
    "def backward_elimination(X, y, significance_level=0.05):\n",
    "    num_features = X.shape[1]\n",
    "    for i in range(num_features):\n",
    "        model = LinearRegression()\n",
    "        model.fit(X, y)\n",
    "        p_values = pd.Series(model.coef_, index=X.columns)\n",
    "        max_p_value = p_values.max()\n",
    "        if max_p_value > significance_level:\n",
    "            index_to_remove = p_values.idxmax()\n",
    "            X = X.drop(index_to_remove, axis=1)\n",
    "        else:\n",
    "            break\n",
    "    return X\n",
    "\n",
    "# Apply backward elimination\n",
    "X_optimal = backward_elimination(X, y)\n",
    "\n",
    "# Fit final model\n",
    "final_model = LinearRegression()\n",
    "final_model.fit(X_optimal, y)\n",
    "\n",
    "# Print coefficients and intercept\n",
    "print(\"Intercept:\", final_model.intercept_)\n",
    "print(\"Coefficients:\", final_model.coef_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8033ddad",
   "metadata": {
    "papermill": {
     "duration": 0.002198,
     "end_time": "2024-03-04T14:44:53.755232",
     "exception": false,
     "start_time": "2024-03-04T14:44:53.753034",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Business Case**: Optimizing Predictive Model for Sales Forecasting\n",
    "Background:\n",
    "Our company, XYZ Retail, operates in the highly competitive retail industry, where accurate sales forecasting is crucial for efficient inventory management, resource allocation, and overall business planning. Inaccurate forecasts can lead to overstocking, stockouts, increased carrying costs, and missed revenue opportunities. To enhance our forecasting capabilities, we aim to develop a robust predictive model that can accurately predict future sales based on historical data and relevant predictor variables.\n",
    "\n",
    "**Problem Statement:**\n",
    "Currently, our sales forecasting process relies on traditional methods that often overlook the complex relationships between various factors influencing sales performance. We need to improve the accuracy and reliability of our forecasts by leveraging advanced statistical modeling techniques.\n",
    "\n",
    "**Objective:**\n",
    "The primary objective of this initiative is to develop a predictive model using backward elimination, a technique that iteratively selects the most significant predictor variables while eliminating irrelevant ones. By doing so, we aim to optimize our predictive model's performance and enhance the accuracy of our sales forecasts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a53af1",
   "metadata": {
    "papermill": {
     "duration": 0.002072,
     "end_time": "2024-03-04T14:44:53.759616",
     "exception": false,
     "start_time": "2024-03-04T14:44:53.757544",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "\"Python/Mu (mu_venv-38-20231109-183720)\"",
   "language": "python",
   "name": "mu_venv-38-20231109-183720"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.241206,
   "end_time": "2024-03-04T14:44:54.382042",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-04T14:44:46.140836",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
